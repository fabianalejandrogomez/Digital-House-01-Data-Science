{
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "hBJi1X3rYqb2"
      },
      "cell_type": "markdown",
      "source": "# PRACTICA GUIADA: Introducción a Machine Learning 1\n\nAhora revisaremos varios ejemplos simples de aplicación de métodos de aprendizaje supervisado y no supervisado"
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DuRbYNZlYqb9"
      },
      "cell_type": "markdown",
      "source": "### Ejemplo de aprendizaje supervisado: Regresión lineal simple\n\nComo ejemplo de este proceso, vamos a considerar una regresión lineal simple, es decir, el caso común de ajustar una línea a datos de la forma $(x, y)$. \n\nVamos a utilizar el dataset de publicidad presentado en el manual 'An Introduction to Statistical Learning with Applications in R' de James, Witten, Hastie, Tibshirani (2013).\n\nPrimero importamos las librerías necesarias para trabajar con datos y visualizar:"
    },
    {
      "metadata": {
        "id": "X9TYqJRdcel2",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\n%matplotlib inline ",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PPeIWcdGcel6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Vamos a importar el dataset de publicidad para nuestro ejemplo de regresión:"
    },
    {
      "metadata": {
        "id": "Gw9pjjmYPFE6",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "710d6776-182f-438d-8e49-a3d375ad1b93",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581525166183,
          "user_tz": 180,
          "elapsed": 6629,
          "user": {
            "displayName": "Pablo Roccatagliata",
            "photoUrl": "",
            "userId": "16888717367980038363"
          }
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "from google.colab import files\nuploaded = files.upload()",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "No module named 'google.colab'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-21dc3c638f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "grkYh85Wcel7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "39b3dc57-f711-4b8b-ee49-d1e64b8659d4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1581525171907,
          "user_tz": 180,
          "elapsed": 816,
          "user": {
            "displayName": "Pablo Roccatagliata",
            "photoUrl": "",
            "userId": "16888717367980038363"
          }
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "advertising = pd.read_csv('Advertising.csv', usecols=[1,2,3,4])\nadvertising.info()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "File b'Advertising.csv' does not exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-90c299a7676d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madvertising\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Advertising.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0madvertising\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    644\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:4184)\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:8449)\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: File b'Advertising.csv' does not exist"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "h_FH3rR7cel-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Vamos a observar las primeras 5 filas de nuestro dataset. \n\nLas primeras 3 columnas representan los gastos de publicidad en miles de USD en diferentes medios (TV, radio y diarios). Estas 3 columnas van a ser nuestras **features**.\n\nLa cuarta columna representa las ventas de un determinado producto en miles de unidades de la empresa que invierte en publicidad. Esta va a ser nuestra variable **target**."
    },
    {
      "metadata": {
        "id": "LnCNYQLgcel_",
        "colab_type": "code",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "advertising.head()",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0mykr8ClcemC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Visualizamos los datos haciendo un pairplot:"
    },
    {
      "metadata": {
        "id": "ruifxgPscemD",
        "colab_type": "code",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "sns.pairplot(advertising);",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jqBNDiaCcemG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Calculamos la matriz de correlación:"
    },
    {
      "metadata": {
        "id": "tqQ14KZPcemH",
        "colab_type": "code",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "advertising.corr()",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aisidyeWcemK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Como nuestro primer objetivo es hacer un modelo de regresión simple, es decir con una sola feature, vamos a elegir la variable TV, ya que es la que muestra una correlación mayor con nuestra variable objetivo.\n\nVamos a hacer un scatter plot entre TV y Sales. El gráfico también nos va a mostrar la recta que se obtiene con una regresión lineal simple:"
    },
    {
      "metadata": {
        "id": "SewR1wI6cemL",
        "colab_type": "code",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "sns.regplot(advertising.TV, advertising.Sales, order=1, ci=None,\\\n                                scatter_kws={'color':'r', 's':9})\nplt.xlim(-10,310)\nplt.ylim(bottom=0);",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "OE8y9bRmYqcQ"
      },
      "cell_type": "markdown",
      "source": "#### 1. Seleccionar una \"clase de modelo\"\n\nEn Scikit-Learn, cada clase de modelo se representa con una clase de Python. \n\nEntonces, por ejemplo, si queremos computar un modelo de regresión lineal simple, podemos importar la clase de regresión lineal de esta forma:"
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "p47YawORYqcT",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LinearRegression",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "iaAM1BxkYqcg"
      },
      "cell_type": "markdown",
      "source": "Notar que también existen otros modelos de regresión lineal más generales; Podés leer más acerca de ellos en la [documentación ``sklearn.linear_model``](http://Scikit-Learn.org/stable/modules/linear_model.html). "
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kH9o-ilTYqcj"
      },
      "cell_type": "markdown",
      "source": "#### 2. Elegir los hiperparámetros del modelo\n\nEs importante destacar que *una clase de modelo no es lo mismo que una instancia de modelo*.\n\nUna vez que hemos decidido nuestra clase de modelo, todavía tenemos que tomar algunas decisiones. Dependiendo de la clase de modelo con la que trabajemos, podríamos tener que responder a una o más preguntas como las siguientes:\n\n- ¿Queremos incluir también un intercepto (intercept = True)?\n- ¿Queremos que el modelo esté normalizado?\n- ¿Queremos agregar features calculados a partir del input para darle mayor flexibilidad al modelo?\n- ¿Qué grado de \"regularización\" vamos a querer usar en el modelo?\n\nEstos son ejemplos de las importantes decisiones que deben hacerse **una vez que hemos seleccionado la clase de modelo a usar**.\n\nEstas elecciones se representan frecuentemente como *hiperparámetros*, o parámetros que deben ser seteados antes de que el modelo sea ajustado a los datos. \n\nEn Scikit-Learn, los hiperparámetros son elegidos como argumentos en la instanciación del modelo. Exploraremos cómo podemos justificar cuantitativamente la elección de hiperparámetros en las próximas clases.  \n\nPara nuestro ejemplo de regresión lineal, podemos instanciar la clase ``LinearRegression`` y especificar que nos gustaría ajustar el intercepto usando el hiperparámetro ``fit_intercept``: "
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6VtBY8okYqcl",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "model = LinearRegression(fit_intercept=True)\nmodel",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ru1vC6pdYqcy"
      },
      "cell_type": "markdown",
      "source": "**Tener en cuenta**: cuando el modelo es instanciado, la única acción que sucede es almacenar los valores de estos valores de hiperparámetros.\n\nEn particular, todavía no hemos aplicado el modelo a ningún dato: la API de Scikit-Learn hace una distinción muy clara entre la *elección del modelo con sus hiperparámetros* y la *aplicación del modelo a los datos*. "
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zeUi31e6Yqc0"
      },
      "cell_type": "markdown",
      "source": "#### 3. Preparar los datos en una matriz de features y un vector de target\n\nPreviamente hemos hablado de la representación de datos de Scikit-Learn, la cual requiere una matriz de features de dos dimensiones y un vector target de una dimensión.\n\nA continuación creamos la matriz de features y el vector target: "
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "boNeWZy9Yqc3",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Creamos X e y\n\nfeature_cols = ['TV']\nX = advertising[feature_cols]\ny = advertising.Sales\n\nprint(\"Shape X:\", X.shape)\nprint(\"Shape y:\", y.shape)\nprint(\"Type X:\", type(X))\nprint(\"Type y:\", type(y))",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gUe26N7scema",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "#### 4. Split entre set de entrenamiento y de testeo\n\nNos gustaría evaluar el modelo en datos que no hayan sido usados en el entrenamiento, por lo tanto vamos a dividir los datos en un *training set* y un *testing set*.\n\nEsto podría hacerse a mano, pero es más conveniente usar la función ``train_test_split``."
    },
    {
      "metadata": {
        "id": "iEnGgpuNcemb",
        "colab_type": "code",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nXtrain, Xtest, ytrain, ytest = train_test_split(X, y,\\\n                                                random_state=1)",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "q21g2iZ1YqdC"
      },
      "cell_type": "markdown",
      "source": "#### 4. Ajustar el modelo a los datos\n\nAhora es momento de aplicar nuestro modelo a los datos.\nEsto puede hacerse con el método ``fit()`` de nuestra instancia de modelo."
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "S3tOYqLgYqdI",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "model.fit(Xtrain, ytrain)",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "2OeIS1SfYqdU"
      },
      "cell_type": "markdown",
      "source": "El método ``fit()`` realiza una secuencia de cómputos internos dependientes del modelo, y los resultados de estas operaciones son almacenadas en atributos específicos de la clase de modelo que el usuario luego puede explorar.\n\nEn Scikit-learn, por convención, todos los atributos que representan los parámetros de los modelos que fueron aprendidos durante el procesos de entrenamiento con ``fit()``, tienen `underscores` en sus nombres; por ejemplo en este modelo lineal, podemos observar el parámetro coef_ y el parámetro intercept_:"
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WPr1EOQyYqdX",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "model.coef_",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DneceQuzYqdm",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "model.intercept_",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "T_T0MJG2Yqdv"
      },
      "cell_type": "markdown",
      "source": "Estos dos parámetros representan la pendiente y el intercepto del ajuste lineal simple a los datos. ¿Cómo interpretamos a estos valores?\n\nUna pregunta que surge frecuentemente se relaciona con incertidumbre o incerteza (uncertainty) en estos parámetros internos del modelo. \n\nEn general, Scikit-Learn no provee herramientas para obtener conclusiones del estado interno de los modelos: interpretar los parámetros de un modelo tiene mucho más que ver con una pregunta de *modelado estadístico* más que una pregunta de *machine learning*.\n\nMachine learning en cambio se enfoca en la calidad con la cual el modelo *predice*.\n\nSi te interesa investigar el significado de los parámetros de ajuste dentro del modelo, existen otras herramientas, incluyendo el paquete de python [Statsmodels](http://statsmodels.sourceforge.net/)."
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "JH9QcMk0Yqdz"
      },
      "cell_type": "markdown",
      "source": "#### 5. Predecir etiquetas para datos desconocidos\n\nUna vez que el modelo es entrenado, la principal tarea en el aprendizaje supervisado es evaluarlo en base a lo que dice acerca de nuevos datos que no fueron parte del **set de entrenamiento**. \n\nEn Scikit-Learn, esto puede hacerse usando el método ``predict()``. \n\nPara ganar intuición, empecemos aplicando la forma manualmente:"
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JyvB5Lj0Yqd2",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Aplicando la fórmula manualmente\n\ntest = 200\n\nmodel.intercept_ + model.coef_*test",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "izevjwFWcemw",
        "colab_type": "code",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "# usando el método del objeto\nimport numpy as np\n\ntest_sklearn = np.array(test).reshape(-1,1)\n\nmodel.predict(test_sklearn)",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "dTa7-0VoYqeI"
      },
      "cell_type": "markdown",
      "source": "Podemos calcular las predicción del modelo para las observaciones en el set de testeo usando el método ``predict()`` de la siguiente forma: "
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RRCRFoTTYqeN",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "ypred = model.predict(Xtest)",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0ryiOOtjYqeZ"
      },
      "cell_type": "markdown",
      "source": "Finalmente, podemos evaluar la bondad de ajuste utilizando las siguientes métricas:"
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4-u6QckgYqeb",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn import metrics\nprint ('MAE:', metrics.mean_absolute_error(ytest, ypred))\nprint ('MSE:', metrics.mean_squared_error(ytest, ypred))\nprint ('RMSE:', np.sqrt(metrics.mean_squared_error(ytest, ypred)))\nprint ('R2:', metrics.r2_score(ytest, ypred))",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H-Zyd-xgcem6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Donde:\n    \n** El error absoluto medio ** (MAE) es la media del valor absoluto de los errores:\n\n$$ \\frac 1n\\sum_ {i = 1}^n |y_i-\\hat{y}_i| $$\n\n** Mean Squared Error ** (MSE) es la media de los errores al cuadrado:\n\n$$ \\frac 1n\\sum_ {i = 1}^n(y_i- \\hat{y}_i)^2 $$\n\n** Error cuadrático medio raíz ** (RMSE) es la raíz cuadrada de la media de los errores al cuadrado:\n\n$$ \\sqrt{\\frac 1n\\sum_{i = 1}^n(y_i- \\hat{y}_i)^2} $$\n\nComparando estas métricas:\n\n- ** MAE **  es el error promedio.\n- ** MSE **  \"penaliza\" errores grandes.\n- ** RMSE **  es interpretable, tiene las mismas unidades  que la \"y\".\n- ** $R^2$ ** es la proporción de la varianza total de $Y$ explicada por el modelo\n\nCon excepción de R2, todas estas son ** funciones de pérdida **, porque queremos minimizarlas."
    },
    {
      "metadata": {
        "id": "iKXEO0GIcem6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "En la clases que vienen vamos a estudiar en profundidad el modelo de regresión lineal. Pasemos ahora a ver un ejemplo de clasificación. "
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-9ySCSxHYqer"
      },
      "cell_type": "markdown",
      "source": "### Ejemplo de aprendizaje supervisado: Default de tarjeta de crédito\n\nVeamos un modelo de clasificación. Este es otro tipo de problema de aprendizaje supervisado pero aquí la variable objetivo es categórica. Queremos predecir si una determinada persona entrará en default en el pago de su tarjeta de crédito, tomando como features su ingreso, la deuda en su tarjeta (balance) y si es estudiante o no.\n\nEste dataset también lo tomamos del manual 'An Introduction to Statistical Learning with Applications in R' de James, Witten, Hastie, Tibshirani (2013)\n"
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NaYmSucxYqey",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Importamos el dataset y visualizamos las primeras 5 filas:\n\ndf = pd.read_excel('Default.xlsx', usecols='B:E')\n\ndf.head()",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PzRoNysEcem-",
        "colab_type": "code",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "default = pd.get_dummies(df.default, prefix='default', prefix_sep='_', drop_first=True)\nstudent = pd.get_dummies(df.student, prefix='student', prefix_sep='_', drop_first=True)",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VxCnyysOcenA",
        "colab_type": "code",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "default.head()",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TBaulj2gYqfA",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "df = pd.concat([df, student, default], axis=1)\ndf.head()",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FRzPvZXthq2h",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Creamos X e y\n\nfeature_cols = ['balance', 'income', 'student_Yes']\nX = df[feature_cols]\ny = df.default_Yes\n\nprint(\"Shape X:\", X.shape)\nprint(\"Shape y:\", y.shape)\nprint(\"Type X:\", type(X))\nprint(\"Type y:\", type(y))",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-OV99MDJYqfW"
      },
      "cell_type": "markdown",
      "source": "Para esta tarea, usaremos un modelo generativo extremadamente simple conocido como Naive Bayes Gausiano, el cuál procede asumiendo que cada clase se construye a partir de una distribución Gausiana. Lo veremos en detalle más adelante en el curso.\n\nPorque es muy rápido y no tiene hiperparámetros para elegir, Naive Bayes Gausiano es frecuentemente un buen modelo para usar como una clasificación baseline, antes de explorar si pueden encontrarse mejoras a través de modelos más sofisticados.\n\nVamos a generar nuestros datasets de entrenamiento y testeo usando la función ``train_test_split``."
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vhbvUmcDYqfa",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nXtrain, Xtest, ytrain, ytest = train_test_split(X, y,\n                                                random_state=1)",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bKqALT_LYqfh"
      },
      "cell_type": "markdown",
      "source": "Con los datos preparados, podemos seguir nuestra receta para predecir las etiquetas:"
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VVl-0CQaYqfn",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.naive_bayes import GaussianNB # 1. elegir la clase de modelo\nmodel = GaussianNB()                       # 2. instanciar el modelo\nmodel.fit(Xtrain, ytrain)                  # 3. ajustar el modelo a los datos\ny_model = model.predict(Xtest)             # 4. predecir a partir de nuevos datos",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "9gT-KeHGYqfu"
      },
      "cell_type": "markdown",
      "source": "Finalmente, podemos usar la función ``accuracy_score`` para estudiar la proporción de etiquetas predichas que coinciden con el valor de verdad correspondiente a esa observación."
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "D4-L4ggGYqfx",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import accuracy_score\naccuracy_score(ytest, y_model)",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "U34MuY1QYqf8"
      },
      "cell_type": "markdown",
      "source": "Con un accuracy del 97,4%, podemos ver que incluso este sencillo algoritmo de clasificación es efectivo para este dataset particular."
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "3i2QW1qbYqf_"
      },
      "cell_type": "markdown",
      "source": "### Ejemplo de aprendizaje no supervisado: Dimensionalidad de Iris\n\nComo un ejemplo de un problema de aprendizaje no supervisado, veamos cómo reducir la dimensionalidad de los datos del dataset Iris para poder visualizarlos más fácilmente.\n\nEl dataset consiste en 50 muestras de 3 especies de la flor iris, de las cuales disponemos 4 features: el largo y ancho del pétalo y del sépalo.\n\nPor lo tanto, el dataset Iris es cuatridimensional: hay cuatro features medidas para cada observación (sample).\n\nLa tarea de reducción de la dimensionalidad es investigar si hay una representación apropiada de baja dimensionalidad que retiene las características esenciales del dataset original. \n\nFrecuentemente la reducción de la dimensionalidad se usa como una ayuda para visualizar datos: después de todo es mucho más fácil plotear datos en dos dimensiones que en cuatro o más dimensiones. \n\nEn este ejemplo vamos a usar Principal Component Analysis (PCA), que es una técnica rápida de reducción lineal de la dimensionalidad. \nVamos a pedirle al modelo que devuelva dos componentes, es decir, una representación bidimensional de los datos. \n\nSiguiendo la secuencia de pasos presentada previamente, tenemos:"
    },
    {
      "metadata": {
        "id": "koenX06ocenY",
        "colab_type": "code",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "# importamos el dataset de la libresría Seaborn:\n\niris = sns.load_dataset('iris')\niris.head()",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gshovkl5cenb",
        "colab_type": "code",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Generamos la matriz de las features:\nX_iris = iris.drop('species', axis=1)\nX_iris.species",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2uh8fhWPYqgB",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 1. Seleccionar la clase de modelo\nfrom sklearn.decomposition import PCA  \n\n# 2. Instanciar el modelo con hiperparámetros\nmodel = PCA(n_components=2)            \n\n# 3. Ajustar a los datos. Notar que no especificamos \"y\" \nmodel.fit(X_iris)                      \n\n# 4. Transformar los datos a dos dimensiones\nX_2D = model.transform(X_iris)         ",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lFb8CM87YqgJ"
      },
      "cell_type": "markdown",
      "source": "Ahora vamos a plotear los resultados. Una forma rápida de hacer esto es insertar los resultados en el ``DataFrame`` original de Iris, y usar el método ``lmplot`` de Seaborn para mostrar los resultados:\n"
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nrsPYCOHYqgO",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "iris['PCA1'] = X_2D[:, 0]\niris['PCA2'] = X_2D[:, 1]\nsns.lmplot(\"PCA1\", \"PCA2\", hue='species', data=iris, fit_reg=False);",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EKChoxyJjLaQ",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "iris.head()",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "P0IXNfq9YqgW"
      },
      "cell_type": "markdown",
      "source": "Vemos que en la representación en dos dimensiones, las especies están relativamente bien separadas, incluso aunque el algoritmo PCA no tenía conocimiento de las etiquetas de las especies de flores! "
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Z_pBPNu9YqgX"
      },
      "cell_type": "markdown",
      "source": "### Aprendizaje no supervisado: Clustering con Iris\n\nVamos a aplicar un algoritmo de clustering al dataset Iris.\n\nUn algoritmo de clustering intenta encontrar grupos distintos sin tener referencias a etiquetas en los datos. \n\nVamos a usar un método poderoso de clustering llamado Gaussian mixture model (GMM). \nUn GMM intenta modelar los datos como una colección de blobs Gausianos. \n\nPodemos ajustar el GMM de la siguiente forma:"
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Hua9z2EQYqgY",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 1. Elegimos la clase de modelo\nfrom sklearn.mixture import GaussianMixture\n\n# 2. Instanciamos el modelo con sus hiperparámetros\nmodel = GaussianMixture(n_components=3,\n            covariance_type='full')  \n\n# 3. Ajustamos a los datos. Notar que \"y\" no es especificada\nmodel.fit(X_iris)                    \n\n# 4. Determinamos las etiquetas de los clusters\ny_gmm = model.predict(X_iris)       ",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "JTQ5_tDqYqgf"
      },
      "cell_type": "markdown",
      "source": "Como antes, agregaremos las etiquetas de los clusters al ``DataFrame`` Iris y usaremos Seaborn para plotear los resultados:"
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VXI9rV2yYqgm",
        "colab": {},
        "trusted": false
      },
      "cell_type": "code",
      "source": "iris['cluster'] = y_gmm\nsns.lmplot(\"PCA1\", \"PCA2\", data=iris, hue='species',\n           col='cluster', fit_reg=False);",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Hstm7CM4Yqg1"
      },
      "cell_type": "markdown",
      "source": "Al separar los datos por número de cluster, vemos exactamente cuán bien el algoritmo GMM ha recuperado la etiqueta subyacente: la especie *setosa* es separada perfectamente, aunque vemos una pequeña porción mezclada entre *versicolor* y *virginica*. \n\nEsto significa que incluso sin un experto que nos diga las etiquetas de las flores individuales, las medidas de estas observaciones son lo suficientemente distintas para que podamos identificar *automáticamente* la prsencia de estos diferentes grupos de especies con un simple algoritmo de clustering. \n\nEste tipo de algoritmo podría incluso darle a los expertos en la disciplina algunas pistas sobre las relaciones entre las muestras que están observando."
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zpjZkdsBYqg8"
      },
      "cell_type": "markdown",
      "source": "## En resumen"
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "CwfCPPpCYqhD"
      },
      "cell_type": "markdown",
      "source": "En esta sección hemos cubierto las características esenciales de la representación de datos en Scikit-Learn y la API de estimadores. \n\nSin importar el tipo de estimador, el mismo patrón de importar/instanciar/fittear/predecir se mantiene en todos los casos. \n\nArmado con esta nueva información sobre la API de estimadores, vos podés explorar la documentación de Scikit-Learn y comenzar a probar varios modelos sobre tus datos. \n\nEn la próxima clase, vamos a explorar el que tal vez es el tópico más importante en machine learning: cómo seleccionar y validar tu modelo. "
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "1_PRACTICA_GUIADA_Intro_ML_Sklearn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}